---
output:
  word_document: default
  html_document: default
---





```{r}
#install.packages("vip")
library(tidymodels)
library(tidymodels)
library(caret)
library(gridExtra)
library(vip)
library(ranger)
include = FALSE
```
data reading and cleaning:
```{r}
drug <- read.csv("drug_data-1.csv")

names(drug) = c("ID", "Age", "Gender", "Education", "Country", "Ethnicity", "Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive", "SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis", "Choc", "Coke", "Crack", "Exstasy", "Heroin", "Ketamine", "Legalh", "LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")

# str(drug)

drug[drug == "CL0"] = "No"
drug[drug == "CL1"] = "No"
drug[drug == "CL2"] = "Yes"
drug[drug == "CL3"] = "Yes"
drug[drug == "CL4"] = "Yes"
drug[drug == "CL5"] = "Yes"
drug[drug == "CL6"] = "Yes"
```

```{r}
drug_clean = drug %>% 
  mutate_at(vars(Age:Ethnicity), funs(as.factor)) %>% 
  mutate(Age = factor(Age, labels = c("18_24", "25_34", "35_44",
"45_54", "55_64", "65_"))) %>% 
  mutate(Gender = factor(Gender, labels = c("Male", "Female"))) %>%
  mutate(Education = factor(Education, labels = c("Under16", "At16", "At17", "At18", "SomeCollege", "ProfessionalCert", "Bachelors", "Masters", "Doctorate"))) %>% 
  mutate(Country = factor(Country, labels = c("USA", "NewZealand", "Other", "Australia", "Ireland","Canada","UK"))) %>% 
  mutate(Ethnicity = factor(Ethnicity, labels = c("Black", "Asian", "White", "White/Black", "Other", "White/Asian", "Black/Asian"))) %>%
  mutate_at(vars(Alcohol:VSA), funs(as.factor)) %>% 
  select(-ID)

# str(drug_clean)
```

```{r}
 drug_clean = drug_clean %>% select(!(Alcohol:Mushrooms)) %>% select(!(Semer:VSA)) 
names(drug_clean)
```

Task 1: Check for missing data in drug_clean dataframe.
```{r}
# summary(drug_clean)
```
There is no missingness in the drug_clean data.

Task 2: Split the data using set.seed(1234)
```{r}
set.seed(1234)
drug_split <- initial_split(drug_clean, prop = 0.7, strata = Nicotine)
train = training(drug_split)
test = testing(drug_split)
```

Task 3: graph each variable with Nicotine.
```{r}
p1 <- ggplot(train, aes(x = Age, fill = Nicotine)) + geom_bar(position = "fill")
p2 <- ggplot(train, aes(x = Education, fill = Nicotine)) + geom_bar(position = "fill")
p3 <- ggplot(train, aes(x = Country, fill = Nicotine)) + geom_bar(position = "fill")
p4 <- ggplot(train, aes(x = Ethnicity, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)
```
```{r}
p5 <- ggplot(train, aes(Nicotine, Nscore)) +
  geom_boxplot()
p6 <- ggplot(train, aes(Nicotine, Escore)) + 
  geom_boxplot()
p7 <- ggplot(train, aes(Nicotine, Oscore)) + 
  geom_boxplot()
p8 <- ggplot(train, aes(Nicotine, Ascore)) + 
  geom_boxplot()
grid.arrange(p5,p6,p7,p8)
```
```{r}
p9 <- ggplot(train, aes(Nicotine, Cscore)) + geom_boxplot()
p10 <- ggplot(train, aes(Nicotine, Impulsive)) + geom_boxplot()
p11 <- ggplot(train, aes(Nicotine, SS)) + geom_boxplot()
p12 <- ggplot(train, aes(x = Gender, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p9,p10,p11,p12)
```
Escore seems to be the only variable that does not affect the nicotine variable. The older you get, the less yes there is. There is variablility in all the other variables in nicotine as well.

Task 4: Random Forest
```{r}
set.seed(123)
rf_folds = vfold_cv(train, v = 5)

drug_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% #add tuning of mtry and min_n parameters
  #setting trees to 100 here should also speed things up a bit, but more trees might be better
  set_engine("ranger", importance = "permutation") %>% #added importance metric
  set_mode("classification")

drug_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(drug_recipe)

rf_grid = grid_regular(
  mtry(range = c(2, 8)), #these values determined through significant trial and error
  min_n(range = c(5, 20)), #these values determined through significant trial and error
  levels = 10
)

set.seed(123)
rf_res_tuned = tune_grid(
  drug_wflow,
  resamples = rf_folds,
  grid = rf_grid #use the tuning grid
)

rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```
Task 5: Use best mtry and n_min to finalize workflow.
```{r}
best_rf = select_best(rf_res_tuned, "accuracy")

final_rf = finalize_workflow(
  drug_wflow,
  best_rf
)

final_rf

#fit the finalized workflow to our training data
final_rf_fit = fit(final_rf, train)

final_rf_fit %>% pull_workflow_fit() %>% vip(geom = "point")
```
The variables most important are SS, Oscore, Country_UK, and Ascore. SS is the sensation seeing, Oscore is the openess to experience, Country_Uk means the participant currently resides in that country, in this case UK. Ascore is the agreeableness.

Task 6: How does the model perform on the training and testing sets?
```{r}
trainpredrf = predict(final_rf_fit, train)
head(trainpredrf)
testpredrf = predict(final_rf_fit, test)
head(testpredrf)

confusionMatrix(trainpredrf$.pred_class, train$Nicotine, 
                positive = "Yes")
```
```{r}
confusionMatrix(testpredrf$.pred_class, test$Nicotine,
                positive = "Yes")
```
The model performs differently on the training vs testing data. The accuracy on the training data is 88% and on the testing data 71%. Both these values are above the naive value of 67% if we just said yes for everyone.

Task 7: 
I would be concerned about using this model in the real world because of how much the accuracy dropped after using it on the testing data. It gives you a slight increase over the naive model. This model would be good in circumstances where it would be better to error on the side of caution where more people are predicted to have used Nicotine. A real world application may be used in advertising campaigns on the side effects of smoking, assuming most people come into contact with Nicotine through smoking. This wouldn't need the highest accuracy model in order to have an effect.
